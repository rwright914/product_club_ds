{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a follow-along from this Medium post: \n",
    "    https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b\n",
    "    \n",
    "Some of the code doesn't work correctly at the moment and I've made minor modifications, but the bulk works well enough to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "#conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Intermediate',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist, Music Analytics',\n",
       " 'Associate Data Scientist, Ads',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist, Mid',\n",
       " 'Data Scientist',\n",
       " 'Staff Data Scientist- Risk',\n",
       " 'Data Scientist (Personalization)',\n",
       " 'People Data Scientist, People Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist, Personalization',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)\n",
    "extract_job_title_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Altice',\n",
       " 'MassMutual',\n",
       " 'Envision LLC',\n",
       " 'IBM',\n",
       " 'Spotify',\n",
       " 'Spotify',\n",
       " 'QuaEra',\n",
       " 'Booz Allen Hamilton',\n",
       " 'INFICON, Inc.',\n",
       " 'States Title',\n",
       " 'The New York Times',\n",
       " 'Uber',\n",
       " 'Amplify Education, Inc.',\n",
       " 'Hungryroot',\n",
       " 'FanDuel']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class':'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return(companies)\n",
    " \n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Long Island City, NY',\n",
       " 'New York, NY 10004 (Financial District area)',\n",
       " 'Buffalo, NY 14201 (Lakeview area)',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY 10018 (Garment District area)',\n",
       " 'Rome, NY 13441',\n",
       " 'East Syracuse, NY 13057',\n",
       " 'New York State',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'Brooklyn, NY',\n",
       " 'New York State',\n",
       " 'New York, NY']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Altice\\n\\n\\n\\n3.4',\n",
       " 'MassMutual\\n\\n\\n\\n3.7',\n",
       " 'Envision LLC\\n\\n\\n\\n3.3',\n",
       " 'IBM\\n\\n\\n\\n3.9',\n",
       " 'Spotify\\n\\n\\n\\n4.3',\n",
       " 'Spotify\\n\\n\\n\\n4.3',\n",
       " 'QuaEra',\n",
       " 'Booz Allen Hamilton\\n\\n\\n\\n3.9',\n",
       " 'INFICON, Inc.',\n",
       " 'States Title\\n\\n\\n\\n3.2',\n",
       " 'The New York Times\\n\\n\\n\\n4.0',\n",
       " 'Uber\\n\\n\\n\\n3.7',\n",
       " 'Amplify Education, Inc.\\n\\n\\n\\n3.9',\n",
       " 'Hungryroot\\n\\n\\n\\n3.5',\n",
       " 'FanDuel\\n\\n\\n\\n4.1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this part doesn't seem to work correctly\n",
    "def extract_salary_from_result(soup): \n",
    "    salaries = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        try:\n",
    "            salaries.append(div.find('nobr').text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name='div', attrs={'class':'sjcl'})\n",
    "                div_three = div_two.find('div')\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append('Nothing_found')\n",
    "    return(salaries)\n",
    "extract_salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'summary'})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return(summaries)\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 100\n",
    "city_set = ['Chicago', 'Houston', 'Miami']\n",
    "columns = ['city', 'job_title', 'company_name', 'location', 'summary', 'salary']\n",
    "sample_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [city, job_title, company_name, location, summary, salary]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:221: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "new_array = []\n",
    "for city in city_set:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        page = requests.get('http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=' + str(city) + '&start=' + str(start))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, 'lxml', from_encoding='utf-8')\n",
    "        for div in soup.find_all(name='div', attrs={'class':'row'}): \n",
    "            #specifying row num for index of job posting in dataframe\n",
    "            num = (len(sample_df) + 1) \n",
    "            #creating an empty list to hold the data for each posting\n",
    "            job_post = [] \n",
    "            #append city name\n",
    "            job_post.append(city) \n",
    "            #grabbing job title\n",
    "            for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "                job_post.append(a['title']) \n",
    "            #grabbing company name\n",
    "            company = div.find_all(name='span', attrs={'class':'company'}) \n",
    "            if len(company) > 0: \n",
    "                for b in company:\n",
    "                    job_post.append(b.text.strip()) \n",
    "            else: \n",
    "                sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "                for span in sec_try:\n",
    "                    job_post.append(span.text) \n",
    "            #grabbing location name\n",
    "            c = div.findAll('span', attrs={'class': 'location'}) \n",
    "            for span in c: \n",
    "                job_post.append(span.text) \n",
    "            #grabbing summary text\n",
    "            d = div.findAll('span', attrs={'class': 'summary'}) \n",
    "            for span in d:\n",
    "                job_post.append(span.text.strip()) \n",
    "            #grabbing salary\n",
    "            try:\n",
    "                job_post.append(div.find('nobr').text) \n",
    "            except:\n",
    "                try:\n",
    "                    div_two = div.find(name='div', attrs={'class':'sjcl'}) \n",
    "                    div_three = div_two.find('div') \n",
    "                    job_post.append(div_three.text.strip())\n",
    "                except:\n",
    "                    job_post.append('Nothing_found') \n",
    "            #appending list of job post info to dataframe at index num\n",
    "            new_array.append(job_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>North American Corporation</td>\n",
       "      <td>Glenview, IL</td>\n",
       "      <td>North American Corporation\\n\\n\\n\\n3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Senior Data Scientist - BAM Ventures</td>\n",
       "      <td>Balyasny</td>\n",
       "      <td>Chicago, IL 60602 (The Loop area)</td>\n",
       "      <td>Balyasny\\n\\n\\n\\n4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Senior Data Scientist - Enterprise Data Science</td>\n",
       "      <td>Blue Cross Blue Shield of IL, MT, NM, OK &amp; TX</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Blue Cross Blue Shield of IL, MT, NM, OK &amp; TX\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Sr.Data Scientist</td>\n",
       "      <td>Sky Consulting Inc</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Sky Consulting Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Underwriters Laboratories Inc.</td>\n",
       "      <td>Northbrook, IL 60062</td>\n",
       "      <td>Underwriters Laboratories Inc.\\n\\n\\n\\n3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Miami</td>\n",
       "      <td>AWS Data Engineer</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Miami, FL 33126 (Flagami area)</td>\n",
       "      <td>Accenture\\n\\n\\n\\n4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Miami, FL 33126 (Flagami area)</td>\n",
       "      <td>Accenture\\n\\n\\n\\n4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Data Governance and Quality Analytics &amp; Cognit...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Miami, FL 33131 (Downtown area)</td>\n",
       "      <td>Deloitte\\n\\n\\n\\n4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Google Cloud Data Engineer</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Miami, FL 33126 (Flagami area)</td>\n",
       "      <td>Accenture\\n\\n\\n\\n4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Senior Machine Learning Engineer - Opportunity...</td>\n",
       "      <td>VMware Engineering</td>\n",
       "      <td>Miami, FL 33134</td>\n",
       "      <td>VMware Engineering\\n\\n\\n\\n4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        city                                          job_title  \\\n",
       "0    Chicago                                     Data Scientist   \n",
       "1    Chicago               Senior Data Scientist - BAM Ventures   \n",
       "2    Chicago    Senior Data Scientist - Enterprise Data Science   \n",
       "3    Chicago                                  Sr.Data Scientist   \n",
       "4    Chicago                                     Data Scientist   \n",
       "..       ...                                                ...   \n",
       "197    Miami                                  AWS Data Engineer   \n",
       "198    Miami                            Data Science Consultant   \n",
       "199    Miami  Data Governance and Quality Analytics & Cognit...   \n",
       "200    Miami                         Google Cloud Data Engineer   \n",
       "201    Miami  Senior Machine Learning Engineer - Opportunity...   \n",
       "\n",
       "                                      company_name  \\\n",
       "0                       North American Corporation   \n",
       "1                                         Balyasny   \n",
       "2    Blue Cross Blue Shield of IL, MT, NM, OK & TX   \n",
       "3                               Sky Consulting Inc   \n",
       "4                   Underwriters Laboratories Inc.   \n",
       "..                                             ...   \n",
       "197                                      Accenture   \n",
       "198                                      Accenture   \n",
       "199                                       Deloitte   \n",
       "200                                      Accenture   \n",
       "201                             VMware Engineering   \n",
       "\n",
       "                              location  \\\n",
       "0                         Glenview, IL   \n",
       "1    Chicago, IL 60602 (The Loop area)   \n",
       "2                          Chicago, IL   \n",
       "3                          Chicago, IL   \n",
       "4                 Northbrook, IL 60062   \n",
       "..                                 ...   \n",
       "197     Miami, FL 33126 (Flagami area)   \n",
       "198     Miami, FL 33126 (Flagami area)   \n",
       "199    Miami, FL 33131 (Downtown area)   \n",
       "200     Miami, FL 33126 (Flagami area)   \n",
       "201                    Miami, FL 33134   \n",
       "\n",
       "                                               summary  \n",
       "0                North American Corporation\\n\\n\\n\\n3.1  \n",
       "1                                  Balyasny\\n\\n\\n\\n4.0  \n",
       "2    Blue Cross Blue Shield of IL, MT, NM, OK & TX\\...  \n",
       "3                                   Sky Consulting Inc  \n",
       "4            Underwriters Laboratories Inc.\\n\\n\\n\\n3.6  \n",
       "..                                                 ...  \n",
       "197                               Accenture\\n\\n\\n\\n4.0  \n",
       "198                               Accenture\\n\\n\\n\\n4.0  \n",
       "199                                Deloitte\\n\\n\\n\\n4.0  \n",
       "200                               Accenture\\n\\n\\n\\n4.0  \n",
       "201                      VMware Engineering\\n\\n\\n\\n4.0  \n",
       "\n",
       "[202 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_array,columns=sample_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
